{"cells":[{"cell_type":"markdown","metadata":{"id":"yNMYU3pVs2Qs"},"source":["#Data Preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"HkrfW-1faGaE"},"source":["## Movie Lens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vgq-DS17A-37"},"outputs":[],"source":["!pip install -U deepctr-torch\n","!pip install --upgrade tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fopNGYOgDugE"},"outputs":[],"source":["!pip show tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34894,"status":"ok","timestamp":1662583426218,"user":{"displayName":"Eloisa HH","userId":"08769837300030588346"},"user_tz":-60},"id":"RgHcBiajyQwx","outputId":"97cd0c6d-07a5-47f4-f5a7-67841306b245"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import torch\n","import tensorflow\n","import keras\n","import pickle\n","\n","from sklearn.metrics import log_loss, roc_auc_score, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from keras_preprocessing.sequence import pad_sequences\n","\n","from deepctr_torch.inputs import SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names\n","from deepctr_torch.models import DeepFM, DCN, xDeepFM\n","from deepctr_torch.models import WDL\n","from deepctr_torch.models.basemodel import BaseModel\n","\n","\n","import random\n","import os\n","from tqdm import tqdm\n","import io\n","import gzip\n","drive.mount('/content/drive/') \n","dir = ('/content/drive/My Drive/Github/Colab Notebooks/UCL/grad_research/cross-domain_rs/ml-1m/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lHFyflJtB9h"},"outputs":[],"source":["#User information\n","unames = ['user_id','gender','age','occupation','zip']\n","users = pd.read_table(dir + 'users.dat', sep='::', \n","                      header=None, names=unames, engine='python')\n","#Rating information\n","rnames = ['user_id','movie_id','rating','timestamp']\n","ratings = pd.read_table(dir + 'ratings.dat', sep='::', header=None, names=rnames, engine='python')\n","\n","#Movie information\n","mnames = ['movie_id','title','genres']\n","movies = pd.read_table(dir + 'movies.dat', sep='::', header=None, names=mnames, engine='python',encoding='ISO-8859-1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmfCIsWsyAFF"},"outputs":[],"source":["data=pd.merge(pd.merge(ratings,users),movies)\n","data['CT'] = data['rating'].apply(lambda x: 1 if x > 3 else 0)\n","data.groupby('CT').count()\n","# data[data['genres']==\"Animation|Children's|Musical|Romance\"].groupby('gender').count()\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K73fXB-HhmUX"},"outputs":[],"source":["def data_process(data_df, dense_features,sparse_features):\n","  # Replace continuous NA data to 0.0\n","  data_df[dense_features] = data_df[dense_features].fillna(0.0)\n","  # Replace discrete NA data to -1\n","  data_df[sparse_features] = data_df[sparse_features].fillna(\"-1\")\n","  for feat in sparse_features:\n","    lbe = LabelEncoder()\n","    data_df[feat] = lbe.fit_transform(data_df[feat])\n","  return data_df[dense_features+sparse_features]\n","\"\"\" 1. Generate the paded and encoded sequence feature of sequence input feature(value 0 is for padding).\n","    2. Generate config of sequence feature with VarLenSparseFeat \"\"\"\n","    \n","def split(x):\n","    key_ans = x.split('|')\n","    for key in key_ans:\n","        if key not in key2index:\n","            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n","            key2index[key] = len(key2index) + 1\n","    return list(map(lambda x: key2index[x], key_ans))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKF2ON_DnKlf"},"outputs":[],"source":["columns = data.columns.values\n","dense_features = [\"timestamp\"]\n","sparse_features = [\"movie_id\", \"user_id\",\"age\", \"occupation\", \"zip\"]\n","target = ['CT']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhWV9Qu8-Nfu"},"outputs":[],"source":["# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n","for feat in sparse_features:\n","    lbe = LabelEncoder()\n","    data[feat] = lbe.fit_transform(data[feat])\n","mms = MinMaxScaler(feature_range=(0, 1))\n","data[dense_features] = mms.fit_transform(data[dense_features])\n","\n","# Preprocess the sequence feture(padding)\n","key2index = {}\n","genres_list = list(map(split, data['genres'].values))\n","genres_length = np.array(list(map(len, genres_list)))\n","max_len = max(genres_length) #6 which means the max genres contains 6 genres\n","# Notice : padding=`post`\n","genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztlu9-Fz-i3I"},"outputs":[],"source":[" # 2.count #unique features for each sparse field and generate feature config for sequence feature\n","\n","fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n","                          for feat in sparse_features] + [DenseFeat(feat, 1, )\n","                                                          for feat in dense_features]\n","\n","varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n","    key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean')]  # Notice : value 0 is for padding for sequence input feature\n","\n","linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n","dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n","\n","feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n","\n","data['genres'] = genres_list"]},{"cell_type":"markdown","source":["## Single Domain Experiment"],"metadata":{"id":"8RgyT247TVnK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"69gTxkr0Fy1Q"},"outputs":[],"source":["female = data[data['gender']=='F']\n","male = data[data['gender']=='M']\n","female = female.drop(['rating','title'],axis = 1)\n","male = male.drop(['gender','rating','title'],axis = 1)"]},{"cell_type":"code","source":["# 3.generate input data for model\n","\n","train, test = train_test_split(female, test_size=0.2)\n","train_model_input = {name: train[name] for name in feature_names}\n","test_model_input = {name: test[name] for name in feature_names}"],"metadata":{"id":"PDD0n4e_TejD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mixed Domain"],"metadata":{"id":"bwxeC0VrC7c7"}},{"cell_type":"code","source":["ftr,fte = train_test_split(female, test_size=0.4)\n","mtr,mte = train_test_split(male, test_size=0.4)\n","train = ftr.append(mtr)\n","test = fte\n","train_model_input = {name: train[name] for name in feature_names}\n","test_model_input = {name: test[name] for name in feature_names}"],"metadata":{"id":"o0Ms1InWgrCJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hrm9BXiC8pOs"},"source":["# Models"]},{"cell_type":"markdown","source":["## FM"],"metadata":{"id":"9ho5GuWehot-"}},{"cell_type":"code","source":["device = 'gpu'\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    print('cuda ready...')\n","    device = 'cuda:0'\n","\n","model = FM(linear_feature_columns, dnn_feature_columns,\n","                device=device)\n","\n","model.compile(\"adagrad\", \"binary_crossentropy\",\n","              metrics=[\"binary_crossentropy\", \"auc\"], )\n","fm_history = model.fit(train_model_input,train[target].values,batch_size=64,epochs=30,verbose=1,validation_split=0.1)\n","\n","pred_ans = model.predict(test_model_input, 64)\n","print(\"\")\n","print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n","print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"],"metadata":{"id":"IcFZjuUThq3N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZaNvS762X1E1"},"source":["## DeepFM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gHXLjzohqA6"},"outputs":[],"source":["epochs = 20\n","\n","search_space = {\n","    \"lr\": 1e-3,\n","    \"batch_size\": 256,\n","    \"l2_reg_embedding\": 0.000005,\n","    \"l2_reg_linear\": 0.000005,\n","    \"l2_reg_dnn\": 0.000005,\n","    \"dnn_hidden_units\": 256,\n","    \"dnn_dropout\": 0.8\n","}"]},{"cell_type":"code","source":["device = 'gpu'\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    print('cuda ready...')\n","    device = 'cuda:0'\n","\n","model = DeepFM(linear_feature_columns, dnn_feature_columns,\n","                task='binary',device=device)\n","\n","model.compile(\"adagrad\", \"binary_crossentropy\",\n","              metrics=[\"binary_crossentropy\", \"auc\"], )\n","deepfm_history = model.fit(train_model_input,train[target].values,batch_size=64,epochs=30,verbose=2,validation_split=0.1)\n","\n","pred_ans = model.predict(test_model_input, 64)\n","print(\"\")\n","print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n","print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"],"metadata":{"id":"qOZjXuiqkrbN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AO5M7sBYAzT"},"source":["## DCN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0E7vYf0ZYMk0"},"outputs":[],"source":[" # 4.Define Model,train,predict and evaluate\n","\n","device = 'cpu'\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    print('cuda ready...')\n","    device = 'cuda:0'\n","\n","model = DCN(linear_feature_columns, dnn_feature_columns,\n","                task='binary',\n","               device=device)\n","\n","model.compile(\"adagrad\", \"binary_crossentropy\",\n","              metrics=[\"binary_crossentropy\", \"auc\"], )\n","dcn_history = model.fit(train_model_input,train[target].values,batch_size=64,epochs=30,verbose=2,validation_split=0.1)\n","\n","pred_ans = model.predict(test_model_input, 64)\n","print(\"\")\n","print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n","print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"]},{"cell_type":"markdown","metadata":{"id":"Htodv0xo9hFH"},"source":["## XDeepFM"]},{"cell_type":"code","source":["\n","device = 'gpu'\n","use_cuda = True\n","if use_cuda and torch.cuda.is_available():\n","    print('cuda ready...')\n","    device = 'cuda:0'\n","\n","xdeepfm_model = xDeepFM(linear_feature_columns, dnn_feature_columns,\n","                task='binary',\n","                device=device)\n","\n","xdeepfm_model.compile(\"adagrad\", \"binary_crossentropy\",\n","              metrics=[\"binary_crossentropy\", \"auc\"], )\n","xdeepfm_history = xdeepfm_model.fit(train_model_input,train[target].values,batch_size=64,epochs=30 ,verbose=2,validation_split=0.1)\n","\n","pred_ans = xdeepfm_model.predict(test_model_input, 64)\n","print(\"\")\n","print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n","print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"],"metadata":{"id":"l2p796z2D953"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyN15Su4tItwRfiG5XqJ1UpR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}